{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nifti_file(file_path):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    img = sitk.ReadImage(file_path)\n",
    "    # 轉為 NumPy 陣列\n",
    "    img_arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    return img_arr\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    \n",
    "    # Get current depth\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    current_depth = img.shape[-1]\n",
    "    \n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "def preprocess_img(file_path):\n",
    "    img = read_nifti_file(file_path)\n",
    "    return resize_volume(img)\n",
    "\n",
    "def show_slices(slices):\n",
    "    fig, axes = plt.subplots(1, len(slices))\n",
    "    for i, slice in enumerate(slices):\n",
    "        axes[i].imshow(slice, cmap=\"gray\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\Users\\\\Gina\\\\Lab\\\\kidney\\\\nnUNet-1\\\\Result'\n",
    "mask_path = os.path.join(data_dir, 'case_00057.nii.gz')\n",
    "\n",
    "data = read_nifti_file(mask_path)\n",
    "resize_data = resize_volume(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original image (black):', len(np.where(data == 0)[0]))\n",
    "print('original image (kidney):', len(np.where(data == 1)[-1]))\n",
    "print('original image (tumor):', np.where(data == 2))\n",
    "print('-' * 20)\n",
    "print('resize image (black):', len(np.where(resize_data == 0)[0]))\n",
    "print('resize image (kidney):', len(np.where(resize_data == 1)[-1]))\n",
    "print('resize image (tumor):', len(np.where(resize_data == 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(img):\n",
    "    tumor_region = np.where(img == 2)\n",
    "\n",
    "    if len(tumor_region[0]) == 0:\n",
    "        return (666, 666, 666), (0, 0, 0)\n",
    "\n",
    "    l_width = min(tumor_region[0])\n",
    "    l_height = min(tumor_region[1])\n",
    "    l_depth = min(tumor_region[2])\n",
    "\n",
    "    r_width = max(tumor_region[0])\n",
    "    r_height = max(tumor_region[1])\n",
    "    r_depth = max(tumor_region[2])\n",
    "\n",
    "    # turn the kidney part to black\n",
    "    # img[np.where(img == 1)] = 0\n",
    "    # img = img[l_width:r_width, l_height:r_height, l_depth:r_depth]\n",
    "\n",
    "    return (l_width, l_height, l_depth), (r_width, r_height, r_depth)\n",
    "\n",
    "def get_tumor_region(file_path):\n",
    "    img = read_nifti_file(file_path)\n",
    "    return get_bounding_box(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示各軸切面\n",
    "b_img = get_bounding_box(data)\n",
    "print('image (tumor):', np.where(b_img == 2))\n",
    "\n",
    "show_slices([b_img[:, :, 0], b_img[:, :, 1], b_img[:, :, 2]])\n",
    "# show_slices([resize_data[:, :, 29], resize_data[:, :, 30], resize_data[:, :, 48]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data For predicting tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import label data\n",
    "with open('C:\\\\Users\\\\Gina\\\\Lab\\\\kidney\\\\kits21\\\\kits21\\\\data\\\\kits.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "label = [ case['tumor_histologic_subtype'] for case in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_type = ['rcc_unclassified',\n",
    "                'urothelial',\n",
    "                'mest',\n",
    "                'collecting_duct_undefined',\n",
    "                'oncocytoma',\n",
    "                'clear_cell_papillary_rcc', \n",
    "                'multilocular_cystic_rcc', \n",
    "                'other', 'wilms', \n",
    "                'angiomyolipoma', 'spindle_cell_neoplasm']\n",
    "\n",
    "drop_idx_img = []\n",
    "for idx, value in enumerate(label):\n",
    "    if value in useless_type:\n",
    "        drop_idx_img.append(idx)\n",
    "\n",
    "print('Useless img:', drop_idx_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input mask\n",
    "data_dir = 'C:\\\\Users\\\\Gina\\\\Lab\\\\kidney\\\\nnUNet-1\\\\Result'\n",
    "mask_path = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    if \"nii.gz\" in file:\n",
    "        # if int(file[5:10]) not in drop_idx_img:\n",
    "        mask_path.append(os.path.join(data_dir, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = []\n",
    "l_width = 666\n",
    "l_height = 666\n",
    "l_depth = 666\n",
    "\n",
    "r_width = 0\n",
    "r_height = 0\n",
    "r_depth = 0\n",
    "\n",
    "bounding_box = []\n",
    "\n",
    "for path in mask_path:\n",
    "    img = read_nifti_file(path)\n",
    "\n",
    "    # get the bounding box\n",
    "    l_box, r_box = get_bounding_box(img)\n",
    "\n",
    "    _box = (r_box[0] - l_box[0], r_box[1] - l_box[1], r_box[2] - l_box[2])\n",
    "    bounding_box.append(_box)\n",
    "    # print('bouding box:', _box)\n",
    "    l_width = min(l_width, l_box[0])\n",
    "    l_height = min(l_height, l_box[1])\n",
    "    l_depth = min(l_depth, l_box[2])\n",
    "\n",
    "    r_width = max(r_width, r_box[0])\n",
    "    r_height = max(r_height, r_box[1])\n",
    "    if r_box[2] > r_depth:\n",
    "        print(r_box[2])\n",
    "    r_depth = max(r_depth, r_box[2])\n",
    "\n",
    "    mask.append(img)\n",
    "\n",
    "# print(f\"left: ({l_width}, {l_height}, {l_depth}), right: ({r_width}, {r_height}, {r_depth})\")\n",
    "\n",
    "mask = np.array(mask)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_width = 666\n",
    "l_height = 666\n",
    "l_depth = 666\n",
    "\n",
    "r_width = 0\n",
    "r_height = 0\n",
    "r_depth = 0\n",
    "\n",
    "max_depth = 0\n",
    "\n",
    "for path in mask_path:\n",
    "    img = read_nifti_file(path)\n",
    "\n",
    "    # get the bounding box\n",
    "    l_box, r_box = get_bounding_box(img)\n",
    "\n",
    "    _box = (r_box[0] - l_box[0], r_box[1] - l_box[1], r_box[2] - l_box[2])\n",
    "    print('bouding box:', _box)\n",
    "    \n",
    "    if _box[2] > max_depth:\n",
    "        max_depth = _box[2]\n",
    "        print('max depth:', max_depth)\n",
    "    # l_width = min(l_width, l_box[0])\n",
    "    # l_height = min(l_height, l_box[1])\n",
    "    # l_depth = min(l_depth, l_box[2])\n",
    "\n",
    "    # r_width = max(r_width, r_box[0])\n",
    "    # r_height = max(r_height, r_box[1])\n",
    "    # if r_box[2] > r_depth:\n",
    "    #     print(r_box[2])\n",
    "    # r_depth = max(r_depth, r_box[2])\n",
    "\n",
    "# print(f\"left: ({l_width}, {l_height}, {l_depth}), right: ({r_width}, {r_height}, {r_depth})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(mask[4] == 2)[2][:10])\n",
    "show_slices([mask[4][:, :, 23 ], mask[4][:, :, 44], mask[4][:, :, 43]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"left: ({l_width}, {l_height}, {l_depth}), right: ({r_width}, {r_height}, {r_depth})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, _ in enumerate(mask):\n",
    "#     if _ is None:\n",
    "#         drop_idx_img.append(idx)\n",
    "#         print(idx, 'has no tumor')\n",
    "\n",
    "# print('drop index:', drop_idx_img[-2:])\n",
    "# mask = np.delete(mask, drop_idx_img[-2:])\n",
    "# print(len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.delete(label, drop_idx_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in mask[:10]:\n",
    "    print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0][42:503, 107:429].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # left: (42, 107, 0), right: (503, 429, 911)\n",
    "    img = img[42:503, 107:429]\n",
    "\n",
    "    # Set the desired depth\n",
    "    desired_depth = 200 // 2\n",
    "    desired_width = 461 // 2\n",
    "    desired_height = 322 // 2\n",
    "    \n",
    "    # Get current depth\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    current_depth = img.shape[-1]\n",
    "\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "\n",
    "    # turn the kidney part to black\n",
    "    img[np.where(img == 1)] = 0\n",
    "\n",
    "    # Rotate\n",
    "    # img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before resizing, the tumor position:')\n",
    "print(np.where(mask[0] == 2)[2][:5])\n",
    "print(np.where(mask[1] == 2)[2][:5])\n",
    "print(np.where(mask[2] == 2)[2][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices([mask[0][:, :, 319 ], mask[0][:, :, 320 ], mask[0][:, :, 321 ]])\n",
    "show_slices([mask[1][:, :, 339 ], mask[1][:, :, 340 ], mask[1][:, :, 338 ]])\n",
    "show_slices([mask[2][:, :, 177 ], mask[2][:, :, 175 ], mask[2][:, :, 176 ]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([ resize_volume(_mask) for _mask in mask ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('after resizing, the tumor position:')\n",
    "print(np.where(mask[0] == 2)[2][:5])\n",
    "print(np.where(mask[1] == 2)[2][:5])\n",
    "print(np.where(mask[2] == 2)[2][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices([mask[0][:, :, 52 ], mask[0][:, :, 53 ], mask[0][:, :, 51 ]])\n",
    "show_slices([mask[1][:, :, 56 ], mask[1][:, :, 55 ], mask[1][:, :, 57 ]])\n",
    "show_slices([mask[2][:, :, 29 ], mask[2][:, :, 23 ], mask[2][:, :, 30 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_rotate(img_numpy):\n",
    "    # define some rotation angles\n",
    "    # angles = [-20, -10, -5, 5, 10, 20]\n",
    "    # pick angles at random\n",
    "    # angle = random.choice(angles)\n",
    "    # rotate volume\n",
    "    # volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "    # volume[volume < 0] = 0.0\n",
    "    # volume[volume > 1] = 1.0\n",
    "    # return volume\n",
    "    \"\"\"\n",
    "    Returns a random rotated array in the same shape\n",
    "    :param img_numpy: 3D numpy array\n",
    "    :param min_angle: in degrees\n",
    "    :param max_angle: in degrees\n",
    "    \"\"\"\n",
    "    min_angle = -20\n",
    "    max_angle = 20\n",
    "\n",
    "    assert img_numpy.ndim == 3, \"provide a 3d numpy array\"\n",
    "    assert min_angle < max_angle, \"min should be less than max val\"\n",
    "    assert min_angle > -360 or max_angle < 360\n",
    "\n",
    "    all_axes = [(1, 0), (1, 2), (0, 2)]\n",
    "    angle = np.random.randint(low=min_angle, high=max_angle+1)\n",
    "    axes_random_id = np.random.randint(low=0, high=len(all_axes))\n",
    "    axes = all_axes[axes_random_id]\n",
    "\n",
    "    return ndimage.rotate(img_numpy, angle, axes=axes)\n",
    "\n",
    "rotated_img = mask[0]\n",
    "rotated_img = scipy_rotate(rotated_img)\n",
    "\n",
    "show_slices([rotated_img[:, :, 52], rotated_img[:, :, 53 ], rotated_img[:, :, 51 ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tumor type used only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dummy = pd.get_dummies(label)\n",
    "print(label_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade used only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_grade = pd.DataFrame([ row['tumor_isup_grade'] for row in data ], columns=['grade'])\n",
    "\n",
    "label_grade[ label_grade <= 2] = 0\n",
    "label_grade[ label_grade > 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = label_grade[label_grade['grade'].isna()].index.tolist()\n",
    "\n",
    "# drop nan grade index\n",
    "print('before, label shape:', label_grade.shape)\n",
    "print('before, mask shape:', mask.shape)\n",
    "\n",
    "label_grade = label_grade.drop(index=drop_index)\n",
    "mask = np.delete(mask, drop_index, axis=0)\n",
    "\n",
    "print('after, label shape:', label_grade.shape)\n",
    "print('after, mask shape:', mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(mask[0] == 2)[2][:5])\n",
    "print(np.where(mask[1] == 2)[2][:5])\n",
    "print(np.where(mask[2] == 2)[2][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('grade:', label_grade.loc[0])\n",
    "show_slices([mask[0][:, :, 52], mask[0][:, :, 53], mask[0][:, :, 54]])\n",
    "\n",
    "print('grade:', label_grade.loc[1])\n",
    "show_slices([mask[1][:, :, 56], mask[1][:, :, 55], mask[1][:, :, 57]])\n",
    "\n",
    "print('grade:', label_grade.loc[2])\n",
    "show_slices([mask[2][:, :, 29], mask[2][:, :, 23], mask[2][:, :, 25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(mask, label_grade, test_size = 0.2)\n",
    "\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train.shape[0], x_val.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts(), '\\n')\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(x_train[0] == 2)[2][:5])\n",
    "print(np.where(x_train[1] == 2)[2][:5])\n",
    "print(np.where(x_train[2] == 2)[2][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices([x_train[0][:, :, 30], x_train[0][:, :, 29], x_train[0][:, :, 31]])\n",
    "show_slices([x_train[1][:, :, 49], x_train[1][:, :, 50], x_train[1][:, :, 51]])\n",
    "show_slices([x_train[2][:, :, 70], x_train[2][:, :, 72], x_train[2][:, :, 71]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(img_numpy):\n",
    "        # define some rotation angles\n",
    "        # angles = [-20, -10, -5, 5, 10, 20]\n",
    "        # pick angles at random\n",
    "        # angle = random.choice(angles)\n",
    "        # rotate volume\n",
    "        # volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        # volume[volume < 0] = 0.0\n",
    "        # volume[volume > 1] = 1.0\n",
    "        # return volume\n",
    "        \"\"\"\n",
    "        Returns a random rotated array in the same shape\n",
    "        :param img_numpy: 3D numpy array\n",
    "        :param min_angle: in degrees\n",
    "        :param max_angle: in degrees\n",
    "        \"\"\"\n",
    "        min_angle = -20\n",
    "        max_angle = 20\n",
    "\n",
    "        assert img_numpy.ndim == 3, \"provide a 3d numpy array\"\n",
    "        assert min_angle < max_angle, \"min should be less than max val\"\n",
    "        assert min_angle > -360 or max_angle < 360\n",
    "\n",
    "        all_axes = [(1, 0), (1, 2), (0, 2)]\n",
    "        angle = np.random.randint(low=min_angle, high=max_angle+1)\n",
    "        axes_random_id = np.random.randint(low=0, high=len(all_axes))\n",
    "        axes = all_axes[axes_random_id]\n",
    "        \n",
    "        return ndimage.rotate(img_numpy, angle, axes=axes)\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float16)\n",
    "    return augmented_volume\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    # Rotate volume\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    # print(volume.get_shape())\n",
    "    label = tf.cast(label, tf.float16)\n",
    "    return volume, label\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    label = tf.cast(label, tf.float16)\n",
    "    return volume, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train.to_numpy()))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val.to_numpy()))\n",
    "\n",
    "batch_size = 3\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # outputs = layers.Dense(units=3, activation=\"softmax\")(x) # type output\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x) # grade output\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=230, height=161, depth=100)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\", tf.keras.metrics.AUC()],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "    # print(i, '. train:', model.history.history[metric])\n",
    "    # print(i, '. val:', model.history.history[\"val_\" + metric])\n",
    "    ax[i].plot(model.history.history[metric])\n",
    "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(\"Model {}\".format(metric))\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # outputs = layers.Dense(units=3, activation=\"softmax\")(x)\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model2 = get_model(width=230, height=161, depth=100)\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "# loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "model2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\", tf.keras.metrics.AUC()],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_classification_2.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100\n",
    "model2.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "    # print(i, '. train:', model.history.history[metric])\n",
    "    # print(i, '. val:', model.history.history[\"val_\" + metric])\n",
    "    ax[i].plot(model2.history.history[metric])\n",
    "    ax[i].plot(model2.history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(\"Model {}\".format(metric))\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09/08\n",
    "* 可以改成分 Low grade, High grade，應該比較好分\n",
    "* 先把tumor這塊切出來，Cube 包起 tumor，只用這 cube，找最小的bounding box，再拉出來看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea397cec91cadfeba1f637b1e229fc5613e21e348c4b388b4145c8bc2692c566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
